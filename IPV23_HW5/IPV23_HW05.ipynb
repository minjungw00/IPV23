{"cells":[{"cell_type":"markdown","source":["\n","# **[2023-1] Image Processing & Vision (55397)**\n","\n","* ### Hak Gu Kim\n","* ### Assistant Professor\n","* ### Graduate School of Advanced Imaging Science, Multimedia & Film (GSAIM)\n","* ### Chung-Ang University\n","* ### Webpage: www.irislab.cau.ac.kr\n"],"metadata":{"id":"17h2G6wX9AMS"}},{"cell_type":"markdown","source":["# **Homework V: Convolutional Neural Networks (CNNs)**\n","\n","* ### **Deadline:** 21 June (Wed) at 11:59pm\n","* ### **Submission:** Upload the zip file to \"과제 및 평가\" on E-class\n","  * **Upload zip file:** ipv23_hw05-student number.zip\n","    * **Python code:** ipv23_hw05-student number.ipynb\n","    * **Report:** ipv23_hw05-student number.pdf  (page limit: 4 pages)\n","  "],"metadata":{"id":"DsqcUtsx9Db5"}},{"cell_type":"markdown","source":["## **[Homework V-0]** Environmental Setting"],"metadata":{"id":"55KCnbql9Oma"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from torch.utils.data import DataLoader\n","\n","import torchvision\n","import torchvision.transforms as transforms"],"metadata":{"id":"lfseYMx1JKxy","executionInfo":{"status":"ok","timestamp":1686178878849,"user_tz":-540,"elapsed":5247,"user":{"displayName":"Hak Gu Kim","userId":"14893909611994281750"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["## **[Homework V-1]** Dataset"],"metadata":{"id":"O30LdlatWDqv"}},{"cell_type":"markdown","source":["## 1-1) MNIST Dataset\n","\n","The MNIST dataset consists of 70,000 28x28 handwritten digits images in 10 classess. 60,000 images for training and 10,000 images for test.\n","\n","- http://yann.lecun.com/exdb/mnist/\n","- https://pytorch.org/vision/stable/generated/torchvision.datasets.KMNIST.html#torchvision.datasets.KMNIST"],"metadata":{"id":"Eu6xu3AcCvWU"}},{"cell_type":"code","execution_count":26,"metadata":{"id":"8j2ldCEJYk-P","executionInfo":{"status":"ok","timestamp":1686180971525,"user_tz":-540,"elapsed":283,"user":{"displayName":"Hak Gu Kim","userId":"14893909611994281750"}}},"outputs":[],"source":["# MNIST Dataset\n","mnist_train = torchvision.datasets.MNIST(root='./', train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n","mnist_test  = torchvision.datasets.MNIST(root='./', train=False, transform=transforms.ToTensor(), target_transform=None, download=True)\n","mnist_train, mnist_val = torch.utils.data.random_split(mnist_train, [50000, 10000])\n","\n","# Data Loader for MNIST\n","mnist_train_loader = DataLoader(mnist_train, batch_size=128, shuffle=True)\n","mnist_val_loader   = DataLoader(mnist_val, batch_size=128, shuffle=False)\n","mnist_test_loader  = DataLoader(mnist_test, batch_size=128, shuffle=False)"]},{"cell_type":"markdown","source":["## 1-2) CIFAR-10\n","\n","The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n","\n","- https://www.cs.toronto.edu/~kriz/cifar.html\n","- https://pytorch.org/vision/stable/generated/torchvision.datasets.CIFAR10.html#torchvision.datasets.CIFAR10"],"metadata":{"id":"ENgvafX9Cy2K"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"HGcXIcCW6M3O"},"outputs":[],"source":["# Define the Transforms for Training Dataset\n","transforms_train = transforms.Compose([\n","  transforms.RandomCrop(32, padding=4),\n","  transforms.RandomHorizontalFlip(),\n","  transforms.ToTensor(),\n","  transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","# Define the Transforms for Testing Dataset\n","transforms_test = transforms.Compose([\n","  transforms.ToTensor(),\n","  transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","# CIFAR-10 Dataset\n","cifar_train = torchvision.datasets.CIFAR10(root='./', train=True, download=True, transform=transforms_train)\n","cifar_test = torchvision.datasets.CIFAR10(root='./', train=False, download=True, transform=transforms_test)\n","\n","# Data Loader for CIFAR-10\n","# cifar_train_loader = DataLoader(cifar_train, batch_size=128, shuffle=True)\n","# cifar_test_loader = DataLoader(cifar_test, batch_size=128, shuffle=False)\n","cifar_train_loader = DataLoader(cifar_train, batch_size=128, shuffle=True, num_workers=2)\n","cifar_test_loader = DataLoader(cifar_test, batch_size=128, shuffle=False, num_workers=2)"]},{"cell_type":"markdown","source":["## **[Homework V-2]** (Practice) Implement Each Component of CNNs\n","\n","- Convolutional Layer\n","- Batch Normalization\n","- Dropout Layer"],"metadata":{"id":"5KkNTDf7C33J"}},{"cell_type":"markdown","source":["## 2-1) Convolutional Layer\n","\n","`nn.Conv2d`: Applies a 2D convolution over an input signal composed of several input planes.\n","\n","- https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html"],"metadata":{"id":"l8MUOO-FDRqc"}},{"cell_type":"markdown","source":["**Parameters for** `nn.Conv2d`\n","- in_channels (int) – Number of channels in the input image\n","\n","- out_channels (int) – Number of channels produced by the convolution\n","\n","- kernel_size (int or tuple) – Size of the convolution filter (kernel)\n","\n","- stride (int or tuple, optional) – Stride of the convolution (Default: `1`)\n","\n","- padding (int, tuple or str, optional) – Padding added to boundaries of the input (Default: `0`)\n","\n","- padding_mode (string, optional) – `zeros`, `reflect`, `replicate` or `circular` (Default: `zeros`)\n","\n","- dilation (int or tuple, optional) – Spacing between kernel elements (Default: `1`)"],"metadata":{"id":"Yz_lhYRNDW4c"}},{"cell_type":"markdown","source":["**Examples**\n","- With square kernels and equal stride:\n","\n","  `conv_layer = nn.Conv2d(16, 33, 3, stride=2)`\n","\n","- non-square kernels and unequal stride and with padding:\n","\n","  `conv_layer = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))`\n","\n","- non-square kernels and unequal stride and with padding and dilation:\n","\n","  `conv_layer = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))`"],"metadata":{"id":"SReKGxZADY9K"}},{"cell_type":"code","source":["# Example of convolutional layer\n","\n","# Input dimension: 1 x 3 x 32 x 32\n","# Convolutional layer: 32 5x5 filters with stride 2, padding 2\n","\n","x = torch.randn(1, 3, 32, 32) # input: x\n","\n","conv_layer = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, stride=2, padding=2)\n","\n","print('Input size:\\n', x.size())\n","print()\n","print('Output size:\\n', conv_layer(x).size())"],"metadata":{"id":"SjfkJOIDDbHf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2-2) Batch Normalization\n","\n","`nn.BatchNorm2d`: Applies Batch Normalization over a 4D input (a mini-batch of 2D inputs with additional channel dimension)\n","\n","- https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html\n","- S. Ioffe and C. Szegedy, Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift, **ICML 2015** [[Link]](http://proceedings.mlr.press/v37/ioffe15.html)"],"metadata":{"id":"vnierdJ9DcUH"}},{"cell_type":"markdown","source":["**Parameters** for `nn.BatchNorm2d`\n","- num_features – $C$ from an expected input of size ($N, C, H, W$)"],"metadata":{"id":"u7a0k7xaDfn8"}},{"cell_type":"markdown","source":["**Example**\n","\n","- With learnable parameters\n","\n","  `bn = nn.BatchNorm2d(100)`\n"],"metadata":{"id":"NvJ_LX65Dhzs"}},{"cell_type":"code","source":["# Batch Normalization\n","\n","x = torch.randn(1, 3, 32, 32)\n","\n","bn = nn.BatchNorm2d(num_features=3)\n","\n","print('Input size:\\n', x.size())\n","print()\n","print('Size of feature after BN:\\n', bn(x).size()) # Please check the output size after the batch normalization whether the size of input is changed or not"],"metadata":{"id":"NGrwIrjdDoN-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **[Homework V-3]** (Practice) Build Simple Convolutional Neural Networks\n","\n","- `nn.Sequential`: A sequential container. Modules will be added to it in the order they are passed in the constructor.\n","- https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html"],"metadata":{"id":"7483tUe4DkF9"}},{"cell_type":"markdown","source":["## 3-1) Define CNNs Architecture\n","\n","- 2 conv layers with 7x7 kernel (Convolution + Batch normalization + ReLU)\n","- 1 fc layer for 10 classes"],"metadata":{"id":"PYljB4n1EBS4"}},{"cell_type":"code","source":["# Model: Simple Convolutional Neural Networks\n","\n","class ConvNet(nn.Module):\n","\n","    def __init__(self):\n","        super(ConvNet, self).__init__()\n","        # 1 input image channel, 32 output channels, 7x7 square convolution, 1 stride\n","        self.conv_layer1 = nn.Sequential(\n","            nn.Conv2d(1, 32, 7),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(),\n","        )\n","        # 32 input image channel, 64 output channels, 7x7 square convolution, 1 stride\n","        self.conv_layer2 = nn.Sequential(\n","            nn.Conv2d(32, 64, 7),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","        )\n","\n","        self.fc = nn.Linear(64*16*16, 10)\n","\n","    def forward(self, x):\n","        out_conv1 = self.conv_layer1(x)\n","        out_conv2 = self.conv_layer2(out_conv1)\n","        feature_1d = torch.flatten(out_conv2, 1)\n","        out = self.fc(feature_1d)\n","        return out\n"],"metadata":{"id":"svbOAiGQEiWa","executionInfo":{"status":"ok","timestamp":1686179037025,"user_tz":-540,"elapsed":298,"user":{"displayName":"Hak Gu Kim","userId":"14893909611994281750"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Using GPU\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","model = ConvNet()\n","model = model.to(device)"],"metadata":{"id":"qAZlEsqyEqic"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3-2) Define Optimizer & Loss\n","- Optimization using stochastic gradient descent (SGD)\n","- Learning rate α=0.01\n","- Loss function: Cross Entropy Loss"],"metadata":{"id":"VbKT8XHjEh7K"}},{"cell_type":"code","source":["# Optimizer: Stochastic Gradient Descent Method\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"],"metadata":{"id":"d60kmY8VE0vH","executionInfo":{"status":"ok","timestamp":1686179055911,"user_tz":-540,"elapsed":310,"user":{"displayName":"Hak Gu Kim","userId":"14893909611994281750"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Define Loss function (Cross Entropy Loss here)\n","\n","loss_fn = nn.CrossEntropyLoss()"],"metadata":{"id":"9ag_vvvVFOdh","executionInfo":{"status":"ok","timestamp":1686179057570,"user_tz":-540,"elapsed":286,"user":{"displayName":"Hak Gu Kim","userId":"14893909611994281750"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["##3-3) Train the Simple CNNs Model\n","- Dataset: MNIST\n","- Epochs = 10"],"metadata":{"id":"MbxJl9jjFS5w"}},{"cell_type":"code","source":["# Train the model\n","total_step = len(mnist_train_loader)\n","epochs = 10\n","for epoch in range(epochs):\n","    for i, (images, labels) in enumerate(mnist_train_loader):  # mini batch for loop\n","        \n","        # Upload to gpu\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        \n","        # Forward pass\n","        outputs = model(images)\n","        loss = loss_fn(outputs, labels)\n","        \n","        # Backward pass & Optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if (i+1) % 100 == 0:\n","            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n","                   .format(epoch+1, epochs, i+1, total_step, loss.item()))"],"metadata":{"id":"Udiwr4k_Ffnc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##3-4) Test the Trained CNNs Model"],"metadata":{"id":"4ShRnU-tFrZX"}},{"cell_type":"code","source":["# Test the model\n","model.eval()\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in mnist_test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        \n","        outputs = model(images)\n","        \n","        _, predicted = torch.max(outputs.data, 1)  # classificatoin model -> get the label prediction of top 1 \n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    print('Accuracy of Simple CNN on MNIST test set: {} %'.format(100 * correct / total))"],"metadata":{"id":"qZs4OU6sF0U1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **[Homework V-4]** Design Your Own Convolutional Neural Networks\n","**References**\n","\n","https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n","\n","https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d\n","\n","\n","**Options**\n","- The number of convolutional layers\n","- Stride & padding & dilation\n","- Various activation functions\n","- Pooling layers (max pool, avg pool)\n","- The number of fully connected layers\n","- The dimension of hidden layers\n","- The size of kernels at each layer\n","- *etc*."],"metadata":{"id":"pEEgEYmRF4J4"}},{"cell_type":"code","source":["# Change the following CNNs architecture\n","\n","class myConvNet(nn.Module):\n","\n","    def __init__(self):\n","        super(myConvNet, self).__init__()\n","        # 3 input image channel, 32 output channels, 7x7 square convolution, 1 stride\n","        self.conv_layer1 = nn.Sequential(\n","            nn.Conv2d(3, 32, 7),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(),\n","        )\n","        # 32 input image channel, 64 output channels, 7x7 square convolution, 1 stride\n","        self.conv_layer2 = nn.Sequential(\n","            nn.Conv2d(32, 64, 7),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","        )\n","\n","        self.fc = nn.Linear(64*20*20, 10)\n","\n","    def forward(self, x):\n","        out_conv1 = self.conv_layer1(x)\n","        out_conv2 = self.conv_layer2(out_conv1)\n","        feature_1d = torch.flatten(out_conv2, 1)\n","        out = self.fc(feature_1d)\n","        return out\n"],"metadata":{"id":"caCYEDDiJV4N","executionInfo":{"status":"ok","timestamp":1686180779971,"user_tz":-540,"elapsed":272,"user":{"displayName":"Hak Gu Kim","userId":"14893909611994281750"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","model = myConvNet()\n","model = model.to(device)"],"metadata":{"id":"vto9LzS_Jymy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##4-1) Train Your CNNs Model\n","You can change the number of epochs, learning rate, optimizer, *etc*."],"metadata":{"id":"jHrFQ1rVKDad"}},{"cell_type":"code","source":["# Optimizer: Stochastic Gradient Descent Method\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n","\n","# Define Loss function\n","loss_fn = nn.CrossEntropyLoss()"],"metadata":{"id":"Zt25_qGLJ2LV","executionInfo":{"status":"ok","timestamp":1686180789337,"user_tz":-540,"elapsed":310,"user":{"displayName":"Hak Gu Kim","userId":"14893909611994281750"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# Train the model\n","total_step = len(cifar_train_loader)\n","epochs = 5\n","for epoch in range(epochs):\n","    for i, (images, labels) in enumerate(cifar_train_loader):  # mini batch for loop\n","        \n","        # Upload to gpu\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        \n","        # Forward pass\n","        outputs = model(images)\n","        loss = loss_fn(outputs, labels)\n","        \n","        # Backward pass & Optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if (i+1) % 100 == 0:\n","            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n","                   .format(epoch+1, epochs, i+1, total_step, loss.item()))"],"metadata":{"id":"Gt-Va_0NKRhb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##4-2) Test the Trained Your CNNs Model\n","Try to acheive the best performance!"],"metadata":{"id":"SdzqgVFuKmKn"}},{"cell_type":"code","source":["# Test the model\n","model.eval()\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in cifar_test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        \n","        outputs = model(images)\n","        \n","        _, predicted = torch.max(outputs.data, 1)  # classificatoin model -> get the label prediction of top 1 \n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    print('Accuracy of Your CNNs on CIFAR-10 test set: {} %'.format(100 * correct / total))"],"metadata":{"id":"g9cJL-QpKq4F"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyOx4vb7bcUYfN+gcDNbOXPC"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}